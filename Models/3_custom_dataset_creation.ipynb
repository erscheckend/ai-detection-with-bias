{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e93ded",
   "metadata": {},
   "source": [
    "# Migration dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168251b",
   "metadata": {},
   "source": [
    "This notebook contains the code I used to compile my own custom dataset on the topic of migration. The texts that can be produced with this code need some post-cleaning, like putting them into the same file, checking if all characters are rendered correctly etc..\n",
    "\n",
    "# Human texts\n",
    "\n",
    "The human texts were taken from the SOCC corpus as published in the file SOCC_gnm_articles.csv, which can be downloaded as part of the SOCC zip from here: https://github.com/sfu-discourse-lab/SOCC/releases\n",
    "\n",
    "- First, the 10'366 articles can be searched for migration terms and only the 466 of them containing at least 2 migration terms will be kept.\n",
    "- Secondly, a zero-shot topic classification step will be applied using a BART-based natural language inference model, classifying texts into four coarse topical categories, including a migration-specific label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Config ---\n",
    "input_path  = \"C:\\\\Users\\\\andre\\\\OneDrive\\\\Desktop\\\\PAN Task 2025\\\\SOCC_data\\\\SOCC_gnm_articles.csv\"\n",
    "filtered_texts = \"C:\\\\Users\\\\andre\\\\OneDrive\\\\Desktop\\\\PAN Task 2025\\\\SOCC_data\\\\SOCC_gnm_articles_migration.csv\"\n",
    "\n",
    "migration_terms = [\n",
    "    \"immigration\", \"immigrant\", \"migrant\", \"migration\",\n",
    "    \"refugee\", \"asylum\", \"border\", \"deportation\",\n",
    "    \"undocumented\", \"illegal\", \"visa\", \"integration\"\n",
    "]\n",
    "\n",
    "# Compile regex patterns (word-boundary aware, case-insensitive)\n",
    "term_patterns = {\n",
    "    term: re.compile(rf\"\\b{re.escape(term)}\\b\", re.IGNORECASE)\n",
    "    for term in migration_terms\n",
    "}\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# --- Function to count distinct matched terms ---\n",
    "def find_migration_terms(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    return [\n",
    "        term for term, pattern in term_patterns.items()\n",
    "        if pattern.search(text)\n",
    "    ]\n",
    "\n",
    "# Apply matching\n",
    "df[\"matched_terms\"] = df[\"article_text\"].apply(find_migration_terms)\n",
    "df[\"n_matched_terms\"] = df[\"matched_terms\"].apply(len)\n",
    "\n",
    "# Filter: at least 2 distinct migration terms\n",
    "df_filtered = df[df[\"n_matched_terms\"] >= 2].copy()\n",
    "\n",
    "# --- Save ---\n",
    "df_filtered.to_csv(filtered_texts, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_filtered)} articles to {filtered_texts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"This article is mainly about immigration or migration policy\",\n",
    "    \"This article is mainly about economics or fiscal policy\",\n",
    "    \"This article is mainly about culture, identity, or values\",\n",
    "    \"This article is mainly about other political or social issues\"\n",
    "]\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_html(text):\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def classify_article(text):\n",
    "    cleaned = clean_html(text)\n",
    "    \n",
    "    result = classifier(\n",
    "        cleaned[:4000],  # safety cap; BART max is 1024 tokens\n",
    "        candidate_labels,\n",
    "        multi_label=False\n",
    "    )\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"zs_top_label\": result[\"labels\"][0],\n",
    "        \"zs_top_score\": result[\"scores\"][0],\n",
    "        \"zs_second_score\": result[\"scores\"][1]\n",
    "    })\n",
    "\n",
    "df = pd.read_csv(filtered_texts)\n",
    "\n",
    "zs_results = df[\"article_text\"].progress_apply(classify_article)\n",
    "\n",
    "df = pd.concat([df, zs_results], axis=1)\n",
    "\n",
    "MIGRATION_LABEL = \"This article is mainly about immigration or migration policy\"\n",
    "\n",
    "df_core = df[\n",
    "    (df[\"zs_top_label\"] == MIGRATION_LABEL) &\n",
    "    (df[\"zs_top_score\"] >= 0.6)\n",
    "]\n",
    "\n",
    "df_peripheral = df[\n",
    "    df[\"article_text\"].str.contains(\n",
    "        r\"\\b(immigration|immigrant|migrant|refugee|asylum)\\b\",\n",
    "        case=False,\n",
    "        regex=True\n",
    "    ) &\n",
    "    ~df.index.isin(df_core.index)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30707fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total articles:\", len(df))\n",
    "print(\"Core migration articles:\", len(df_core))\n",
    "print(\"Peripheral migration articles:\", len(df_peripheral))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725237f6",
   "metadata": {},
   "source": [
    "# AI generated texts\n",
    "\n",
    "The AI generated texts were generated by sending one of three prompts at random to openai, gemini or deepseek. To run this code, you will have to enter your own API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a910f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = #enter your API key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "PROMPTS = [\n",
    "    \"Write a newspaper opinion piece about immigration.\",\n",
    "    \"Write an editorial on immigration for a general newspaper audience.\",\n",
    "    \"Write a commentary article discussing immigration policy and society.\"\n",
    "]\n",
    "\n",
    "def trim_to_last_sentence(text, max_len):\n",
    "    text = text[:max_len]\n",
    "    matches = list(re.finditer(r'[.!?][\"\\']?\\s', text))\n",
    "    if matches:\n",
    "        return text[:matches[-1].end()].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def generate_text(min_len, max_len, model=\"gpt-4o-mini\"):\n",
    "    target_length = random.randint(min_len, max_len)\n",
    "    base_prompt = random.choice(PROMPTS)\n",
    "\n",
    "    prompt = (\n",
    "        f\"{base_prompt} \"\n",
    "        f\"Suitable for publication in a general-interest newspaper. \"\n",
    "        f\"Length: approximately {target_length} characters.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional newspaper columnist.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    text = trim_to_last_sentence(text, target_length)\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"target_length\": target_length,\n",
    "        \"actual_length\": len(text),\n",
    "        \"model\": model\n",
    "    }\n",
    "\n",
    "samples = []\n",
    "\n",
    "distributions = [\n",
    "    (25, 1500, 3500),\n",
    "    (50, 3500, 5500),\n",
    "    (25, 5500, 7500)\n",
    "]\n",
    "\n",
    "for count, min_len, max_len in distributions:\n",
    "    for _ in tqdm(range(count), desc=f\"{min_len}-{max_len} chars\"):\n",
    "        sample = generate_text(min_len, max_len)\n",
    "        samples.append(sample)\n",
    "\n",
    "        output_file = \"gpt_immigration_texts.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"model\", \"target_length\", \"actual_length\", \"text\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples)\n",
    "\n",
    "print(f\"Saved {len(samples)} texts to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd15968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "# ---- DeepSeek API setup ----\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = #enter your API key\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "# ---- Prompts ----\n",
    "PROMPTS = [\n",
    "    \"Write a newspaper opinion piece about immigration.\",\n",
    "    \"Write an editorial on immigration for a general newspaper audience.\",\n",
    "    \"Write a commentary article discussing immigration policy and society.\"\n",
    "]\n",
    "\n",
    "# ---- Trimming ----\n",
    "def trim_to_last_sentence(text, max_len):\n",
    "    text = text[:max_len]\n",
    "    matches = list(re.finditer(r'[.!?][\"\\']?\\s', text))\n",
    "    if matches:\n",
    "        return text[:matches[-1].end()].strip()\n",
    "    return text.strip()\n",
    "\n",
    "# ---- Generation ----\n",
    "def generate_text(min_len, max_len, model=\"deepseek-chat\"):\n",
    "    target_length = random.randint(min_len, max_len)\n",
    "    base_prompt = random.choice(PROMPTS)\n",
    "\n",
    "    prompt = (\n",
    "        f\"{base_prompt} \"\n",
    "        f\"Suitable for publication in a general-interest newspaper. \"\n",
    "        f\"Length: approximately {target_length} characters.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional newspaper columnist.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    text = trim_to_last_sentence(text, target_length)\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"target_length\": target_length,\n",
    "        \"actual_length\": len(text),\n",
    "        \"model\": model\n",
    "    }\n",
    "\n",
    "# ---- Sampling ----\n",
    "samples = []\n",
    "\n",
    "distributions = [\n",
    "    (25, 1500, 3500),\n",
    "    (50, 3500, 5500),\n",
    "    (25, 5500, 7500)\n",
    "]\n",
    "\n",
    "for count, min_len, max_len in distributions:\n",
    "    for _ in tqdm(range(count), desc=f\"{min_len}-{max_len} chars\"):\n",
    "        samples.append(generate_text(min_len, max_len))\n",
    "\n",
    "# ---- Save ----\n",
    "output_file = \"deepseek_immigration_texts.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"model\", \"target_length\", \"actual_length\", \"text\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples)\n",
    "\n",
    "print(f\"Saved {len(samples)} texts to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ---- Gemini API setup ----\n",
    "os.environ[\"GEMINI_API_KEY\"] = #enter your API key\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-flash-lite-latest\")\n",
    "\n",
    "# ---- Prompts ----\n",
    "PROMPTS = [\n",
    "    \"Write a newspaper opinion piece about immigration.\",\n",
    "    \"Write an editorial on immigration for a general newspaper audience.\",\n",
    "    \"Write a commentary article discussing immigration policy and society.\"\n",
    "]\n",
    "\n",
    "# ---- Trimming ----\n",
    "def trim_to_last_sentence(text, max_len):\n",
    "    text = text[:max_len]\n",
    "    matches = list(re.finditer(r'[.!?][\"\\']?\\s', text))\n",
    "    if matches:\n",
    "        return text[:matches[-1].end()].strip()\n",
    "    return text.strip()\n",
    "\n",
    "# ---- Generation ----\n",
    "def generate_text(min_len, max_len):\n",
    "    target_length = random.randint(min_len, max_len)\n",
    "    base_prompt = random.choice(PROMPTS)\n",
    "\n",
    "    prompt = (\n",
    "        f\"{base_prompt} \"\n",
    "        f\"Suitable for publication in a general-interest newspaper. \"\n",
    "        f\"Length: approximately {target_length} characters.\"\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.8\n",
    "        }\n",
    "    )\n",
    "\n",
    "    text = response.text\n",
    "    text = trim_to_last_sentence(text, target_length)\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"target_length\": target_length,\n",
    "        \"actual_length\": len(text),\n",
    "        \"model\": \"gemini-pro\"\n",
    "    }\n",
    "\n",
    "# ---- Sampling ----\n",
    "samples = []\n",
    "\n",
    "distributions = [\n",
    "    (25, 1500, 3500),\n",
    "    (50, 3500, 5500),\n",
    "    (25, 5500, 7500)\n",
    "]\n",
    "\n",
    "for count, min_len, max_len in distributions:\n",
    "    for _ in tqdm(range(count), desc=f\"{min_len}-{max_len} chars\"):\n",
    "        samples.append(generate_text(min_len, max_len))\n",
    "\n",
    "# ---- Save ----\n",
    "output_file = \"gemini_immigration_texts.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"model\", \"target_length\", \"actual_length\", \"text\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples)\n",
    "\n",
    "print(f\"Saved {len(samples)} texts to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
