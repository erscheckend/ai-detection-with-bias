{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a361fd",
   "metadata": {
    "id": "81a361fd"
   },
   "source": [
    "# Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a46eba3",
   "metadata": {
    "id": "9a46eba3"
   },
   "outputs": [],
   "source": [
    "# --- Set up environment ---\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "from torch import argmax\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0d2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 39.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 54.4 MB/s  0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e0f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_pan = \"C://Users//andre//OneDrive//Desktop//PAN Task 2025//train//train.jsonl\"\n",
    "testing_data_pan = \"C://Users//andre//OneDrive//Desktop//PAN Task 2025//train//val.jsonl\"\n",
    "training_data_migration = \"C://Users//andre//OneDrive//Desktop//PAN Task 2025//SOCC_data//migration_texts_both_train.xlsx\"\n",
    "testing_data_migration = \"C://Users//andre//OneDrive//Desktop//PAN Task 2025//SOCC_data//migration_texts_both_test.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b66574",
   "metadata": {},
   "source": [
    "# Baseline model on PAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac835acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23707/23707 [32:48<00:00, 12.05it/s]\n",
      "100%|██████████| 23707/23707 [00:32<00:00, 732.24it/s] \n",
      "100%|██████████| 23707/23707 [00:08<00:00, 2944.71it/s]\n",
      "100%|██████████| 23707/23707 [00:05<00:00, 4585.32it/s]\n",
      "100%|██████████| 23707/23707 [00:19<00:00, 1222.54it/s]\n",
      "100%|██████████| 23707/23707 [00:13<00:00, 1798.40it/s]\n",
      "100%|██████████| 23707/23707 [00:10<00:00, 2325.50it/s]\n",
      "100%|██████████| 23707/23707 [00:24<00:00, 964.43it/s] \n",
      "100%|██████████| 23707/23707 [00:17<00:00, 1371.26it/s]\n",
      "100%|██████████| 3589/3589 [04:49<00:00, 12.40it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1235.43it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2629.44it/s]\n",
      "100%|██████████| 3589/3589 [00:00<00:00, 6417.69it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1289.63it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2008.22it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2160.12it/s]\n",
      "100%|██████████| 3589/3589 [00:03<00:00, 1060.48it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1481.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(23707, 38) (3589, 38)\n",
      "[[1169  108]\n",
      " [  64 2248]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep original and metadata\n",
    "train_path = Path(training_data_pan)\n",
    "val_path = Path(testing_data_pan)\n",
    "\n",
    "df_train = pd.read_json(train_path, lines=True)\n",
    "df_train = df_train[[\"id\", \"text\", \"label\", \"genre\", \"model\"]].copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "# --- Train full baseline model ---\n",
    "\n",
    "# Apply spaCy to get all tokens, POS tags, etc.\n",
    "df_train[\"spacy_doc\"] = df_train[\"text\"].progress_apply(nlp)\n",
    "\n",
    "# Baseline features for TRAIN\n",
    "baseline_df = pd.concat([\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_train[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_train[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_handcrafted_scaled = scaler.fit_transform(baseline_df)\n",
    "X_handcrafted_sparse = sparse.csr_matrix(X_handcrafted_scaled)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000, verbose=1)\n",
    "clf.fit(X_handcrafted_sparse, df_train[\"label\"])\n",
    "\n",
    "# --- Validate ---\n",
    "\n",
    "df_val = pd.read_json(val_path, lines=True)\n",
    "df_val[\"spacy_doc\"] = df_val[\"text\"].progress_apply(nlp)\n",
    "\n",
    "# baseline features for VAL\n",
    "baseline_val = pd.concat([\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_val[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_val[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Scale features with SAME scaler\n",
    "X_handcrafted_scaled_val = scaler.transform(baseline_val)\n",
    "X_handcrafted_sparse_val = sparse.csr_matrix(X_handcrafted_scaled_val)\n",
    "\n",
    "# Predict\n",
    "y_val_pred = clf.predict(X_handcrafted_sparse_val)\n",
    "\n",
    "df_val = df_val.copy()\n",
    "df_val[\"y_true\"] = df_val[\"label\"]\n",
    "df_val[\"y_pred\"] = y_val_pred\n",
    "\n",
    "# Evaluate\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(\n",
    "        df_val[\"label\"], y_val_pred,\n",
    "        target_names=[\"Human\", \"AI\"],\n",
    "        output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Sanity check\n",
    "print(baseline_df.isna().sum().sum())\n",
    "print(baseline_val.isna().sum().sum())\n",
    "print(baseline_df.shape, baseline_val.shape)\n",
    "print(confusion_matrix(df_val[\"label\"], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1693de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved baseline model report to: 1_baseline_model_pan_results.xlsx\n",
      "              precision    recall  f1-score      support\n",
      "Human          0.948094  0.915427  0.931474  1277.000000\n",
      "AI             0.954160  0.972318  0.963153  2312.000000\n",
      "accuracy       0.952076  0.952076  0.952076     0.952076\n",
      "macro avg      0.951127  0.943873  0.947314  3589.000000\n",
      "weighted avg   0.952001  0.952076  0.951882  3589.000000\n",
      "Saved 172 misclassifications to baseline_pan_misclassifications.xlsx\n",
      "\n",
      "Top features pushing toward AI:\n",
      "             feature    weight\n",
      "26         upos_PRON  2.843443\n",
      "5            punct_,  1.470360\n",
      "21               ttr  1.406904\n",
      "28          upos_DET  1.124349\n",
      "2      mean_word_len  1.086647\n",
      "36   rep_5gram_ratio  0.904316\n",
      "37  self_sim_jaccard  0.888103\n",
      "0      mean_sent_len  0.652200\n",
      "19       digit_ratio  0.556874\n",
      "11           punct_'  0.435686\n",
      "34         upos_PART  0.391804\n",
      "3       std_word_len  0.355190\n",
      "9            punct_?  0.114997\n",
      "17       upper_ratio  0.057353\n",
      "30        upos_SCONJ  0.033016\n",
      "12           punct_\"  0.023750\n",
      "6            punct_. -0.013307\n",
      "16           punct_… -0.022215\n",
      "8            punct_: -0.022722\n",
      "13           punct_( -0.047620\n",
      "\n",
      "Top features pushing toward Human:\n",
      "           feature    weight\n",
      "4   stopword_ratio -3.621120\n",
      "7          punct_; -1.504417\n",
      "35      upos_PROPN -1.285680\n",
      "15         punct_- -1.240677\n",
      "1     std_sent_len -1.150756\n",
      "20     space_ratio -1.017590\n",
      "31        upos_NUM -0.902325\n",
      "24        upos_ADJ -0.695302\n",
      "23       upos_VERB -0.620994\n",
      "25        upos_ADV -0.478760\n",
      "33       upos_INTJ -0.463896\n",
      "32        upos_AUX -0.370075\n",
      "22       upos_NOUN -0.338835\n",
      "10         punct_! -0.248612\n",
      "14         punct_) -0.110865\n",
      "29      upos_CCONJ -0.094989\n",
      "27        upos_ADP -0.085844\n",
      "18     title_ratio -0.062135\n",
      "13         punct_( -0.047620\n",
      "8          punct_: -0.022722\n"
     ]
    }
   ],
   "source": [
    "# --- Analysis ---\n",
    "# Full report\n",
    "full_results_output_path = Path(\"1_baseline_model_pan_results.xlsx\")\n",
    "report_df.to_excel(full_results_output_path, index=True)\n",
    "\n",
    "print(f\"\\nSaved baseline model report to: {full_results_output_path}\")\n",
    "print(report_df)\n",
    "\n",
    "# Misclassifications\n",
    "misclassified = df_val[df_val[\"y_true\"] != df_val[\"y_pred\"]]\n",
    "misclassified_feats = baseline_val.loc[misclassified.index]\n",
    "\n",
    "misclassified_full = pd.concat(\n",
    "    [misclassified[[\"id\", \"text\", \"y_true\", \"y_pred\", \"model\", \"genre\"]],\n",
    "     misclassified_feats],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "missclassifications_output_path = Path(\"baseline_pan_misclassifications.xlsx\")\n",
    "misclassified_full.to_excel(missclassifications_output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(misclassified_full)} misclassifications to {missclassifications_output_path}\")\n",
    "\n",
    "# Check what the baseline classifier learned\n",
    "handcrafted_df = baseline_df \n",
    "handcrafted_feat_names = list(handcrafted_df.columns)\n",
    "coefs = clf.coef_[0]   # shape = (n_features,)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": handcrafted_feat_names,\n",
    "    \"weight\": coefs\n",
    "})\n",
    "\n",
    "top_ai = coef_df.sort_values(\"weight\", ascending=False).head(20)\n",
    "top_human = coef_df.sort_values(\"weight\", ascending=True).head(20)\n",
    "\n",
    "print(\"\\nTop features pushing toward AI:\")\n",
    "print(top_ai)\n",
    "\n",
    "print(\"\\nTop features pushing toward Human:\")\n",
    "print(top_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0024f74",
   "metadata": {},
   "source": [
    "# Baseline model on migration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43916f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [00:47<00:00, 11.09it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 712.02it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 1994.16it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 4790.03it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 955.76it/s] \n",
      "100%|██████████| 522/522 [00:00<00:00, 1454.03it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 2113.83it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 694.19it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 833.19it/s] \n",
      "100%|██████████| 78/78 [00:06<00:00, 11.53it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1032.32it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 2686.93it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 5521.52it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1109.97it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1770.61it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 2381.62it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 979.61it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1299.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(522, 38) (78, 38)\n",
      "[[38  0]\n",
      " [ 0 40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep original and metadata\n",
    "train_path = Path(training_data_migration)\n",
    "val_path = Path(testing_data_migration)\n",
    "\n",
    "df_train = pd.read_excel(train_path)\n",
    "df_train = df_train[[\"id\", \"text\", \"label\", \"genre\", \"model\"]].copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "# --- Train full baseline model ---\n",
    "\n",
    "# Apply spaCy to get all tokens, POS tags, etc.\n",
    "df_train[\"spacy_doc\"] = df_train[\"text\"].progress_apply(nlp)\n",
    "\n",
    "# Baseline features for TRAIN\n",
    "baseline_df = pd.concat([\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_train[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_train[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_handcrafted_scaled = scaler.fit_transform(baseline_df)\n",
    "X_handcrafted_sparse = sparse.csr_matrix(X_handcrafted_scaled)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000, verbose=1)\n",
    "clf.fit(X_handcrafted_sparse, df_train[\"label\"])\n",
    "\n",
    "# --- Validate ---\n",
    "df_val = pd.read_excel(val_path)\n",
    "\n",
    "df_val[\"spacy_doc\"] = df_val[\"text\"].progress_apply(nlp)\n",
    "\n",
    "# baseline features for VAL\n",
    "baseline_val = pd.concat([\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_val[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_val[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Scale features with SAME scaler\n",
    "X_handcrafted_scaled_val = scaler.transform(baseline_val)\n",
    "X_handcrafted_sparse_val = sparse.csr_matrix(X_handcrafted_scaled_val)\n",
    "\n",
    "# Predict\n",
    "y_val_pred = clf.predict(X_handcrafted_sparse_val)\n",
    "\n",
    "# Evaluate\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(\n",
    "        df_val[\"label\"], y_val_pred,\n",
    "        target_names=[\"Human\", \"AI\"],\n",
    "        output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Sanity check results\n",
    "print(baseline_df.isna().sum().sum())\n",
    "print(baseline_val.isna().sum().sum())\n",
    "print(baseline_df.shape, baseline_val.shape)\n",
    "\n",
    "print(confusion_matrix(df_val[\"label\"], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e873b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved full classification report to: 1_baseline_model_migration_db_results.xlsx\n",
      "              precision  recall  f1-score  support\n",
      "Human               1.0     1.0       1.0     38.0\n",
      "AI                  1.0     1.0       1.0     40.0\n",
      "accuracy            1.0     1.0       1.0      1.0\n",
      "macro avg           1.0     1.0       1.0     78.0\n",
      "weighted avg        1.0     1.0       1.0     78.0\n",
      "\n",
      "Top features pushing toward AI:\n",
      "            feature    weight\n",
      "5           punct_,  0.657379\n",
      "22        upos_NOUN  0.626643\n",
      "3      std_word_len  0.621383\n",
      "26        upos_PRON  0.582140\n",
      "2     mean_word_len  0.461726\n",
      "12          punct_\"  0.426033\n",
      "28         upos_DET  0.340927\n",
      "29       upos_CCONJ  0.300897\n",
      "23        upos_VERB  0.230893\n",
      "21              ttr  0.206724\n",
      "24         upos_ADJ  0.134342\n",
      "8           punct_:  0.083334\n",
      "6           punct_.  0.042621\n",
      "16          punct_…  0.000000\n",
      "7           punct_;  0.000000\n",
      "10          punct_! -0.037683\n",
      "33        upos_INTJ -0.060109\n",
      "9           punct_? -0.067773\n",
      "25         upos_ADV -0.085508\n",
      "36  rep_5gram_ratio -0.195342\n",
      "\n",
      "Top features pushing toward Human:\n",
      "             feature    weight\n",
      "35        upos_PROPN -0.735148\n",
      "15           punct_- -0.734589\n",
      "11           punct_' -0.727390\n",
      "18       title_ratio -0.663105\n",
      "17       upper_ratio -0.632454\n",
      "31          upos_NUM -0.561319\n",
      "1       std_sent_len -0.509759\n",
      "32          upos_AUX -0.446126\n",
      "19       digit_ratio -0.444154\n",
      "37  self_sim_jaccard -0.405192\n",
      "20       space_ratio -0.394657\n",
      "30        upos_SCONJ -0.387993\n",
      "27          upos_ADP -0.386094\n",
      "34         upos_PART -0.373883\n",
      "0      mean_sent_len -0.316033\n",
      "4     stopword_ratio -0.296349\n",
      "14           punct_) -0.243967\n",
      "13           punct_( -0.243967\n",
      "36   rep_5gram_ratio -0.195342\n",
      "25          upos_ADV -0.085508\n"
     ]
    }
   ],
   "source": [
    "# --- Analysis ---\n",
    "# Full report\n",
    "output_path = Path(\"1_baseline_model_migration_db_results.xlsx\")\n",
    "report_df.to_excel(output_path, index=True)\n",
    "\n",
    "print(f\"\\nSaved full classification report to: {output_path}\")\n",
    "print(report_df)\n",
    "\n",
    "# Check what the baseline classifier learned\n",
    "handcrafted_df = baseline_df\n",
    "handcrafted_feat_names = list(handcrafted_df.columns)\n",
    "coefs = clf.coef_[0] # shape = (n_features,)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": handcrafted_feat_names,\n",
    "    \"weight\": coefs\n",
    "})\n",
    "top_ai = coef_df.sort_values(\"weight\", ascending=False).head(20)\n",
    "top_human = coef_df.sort_values(\"weight\", ascending=True).head(20)\n",
    "\n",
    "print(\"\\nTop features pushing toward AI:\")\n",
    "print(top_ai)\n",
    "print(\"\\nTop features pushing toward Human:\")\n",
    "print(top_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe72c70",
   "metadata": {},
   "source": [
    "# Bias model on PAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ff3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23707/23707 [00:15<00:00, 1506.26it/s]\n",
      "100%|██████████| 23707/23707 [02:51<00:00, 138.20it/s]\n",
      "100%|██████████| 23707/23707 [00:07<00:00, 3296.95it/s]\n",
      "100%|██████████| 23707/23707 [00:14<00:00, 1671.21it/s]\n",
      "100%|██████████| 23707/23707 [00:08<00:00, 2864.95it/s]\n",
      "100%|██████████| 23707/23707 [00:16<00:00, 1412.47it/s]\n",
      "100%|██████████| 23707/23707 [00:14<00:00, 1659.57it/s]\n",
      "100%|██████████| 23707/23707 [00:16<00:00, 1421.65it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1565.04it/s]\n",
      "100%|██████████| 3589/3589 [00:24<00:00, 144.47it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2899.33it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1696.64it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2804.05it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1513.17it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 1944.07it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1444.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(23707, 17) (3589, 17)\n",
      "[[ 967  310]\n",
      " [ 252 2060]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep original and metadata\n",
    "train_path = Path(training_data_pan)\n",
    "val_path = Path(testing_data_pan)\n",
    "\n",
    "# --- Train bias model ---\n",
    "df_train = pd.read_json(train_path, lines=True)\n",
    "df_train = df_train[[\"id\", \"text\", \"label\", \"genre\", \"model\"]].copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "# Load lexicons\n",
    "positive_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\positive-words-dictionary.txt\")\n",
    "negative_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\negative-words-dictionary.txt\")\n",
    "profanity_lexicon = features.load_profanity_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\toxic-words-dictionary.txt\")\n",
    "\n",
    "# Bias features for TRAIN\n",
    "bias_df = pd.concat([\n",
    "    df_train[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_sentiment_features),  # already multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_identity_term_rates),  # multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),  # multi-col (pos_rate, neg_rate, polarity_score)\n",
    "    df_train[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Scale features\n",
    "scaler_bias = StandardScaler()\n",
    "X_train_bias = scaler_bias.fit_transform(bias_df)\n",
    "\n",
    "# Train classifier\n",
    "clf_bias = LogisticRegression(max_iter=1000, verbose=1)\n",
    "clf_bias.fit(X_train_bias, df_train[\"label\"])\n",
    "\n",
    "# Bias features for VAL\n",
    "df_val = pd.read_json(val_path, lines=True)\n",
    "\n",
    "bias_val = pd.concat([\n",
    "    df_val[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_sentiment_features),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_identity_term_rates),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),\n",
    "    df_val[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Scale using SAME scaler\n",
    "X_val_bias = scaler_bias.transform(bias_val)\n",
    "\n",
    "# Predict\n",
    "y_val_pred = clf_bias.predict(X_val_bias)\n",
    "\n",
    "df_val = df_val.copy()\n",
    "df_val[\"y_true\"] = df_val[\"label\"]\n",
    "df_val[\"y_pred_bias\"] = y_val_pred\n",
    "\n",
    "# Evaluate\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(\n",
    "        df_val[\"label\"], y_val_pred,\n",
    "        target_names=[\"Human\", \"AI\"],\n",
    "        output_dict=True\n",
    "    )\n",
    ").transpose()\n",
    "\n",
    "# Sanity check\n",
    "print(bias_df.isna().sum().sum())\n",
    "print(bias_val.isna().sum().sum())\n",
    "print(bias_df.shape, bias_val.shape)\n",
    "print(confusion_matrix(df_val[\"label\"], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be7c8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved bias model report to: 2_bias_model_pan_results.xlsx\n",
      "              precision    recall  f1-score     support\n",
      "Human          0.793273  0.757244  0.774840  1277.00000\n",
      "AI             0.869198  0.891003  0.879966  2312.00000\n",
      "accuracy       0.843410  0.843410  0.843410     0.84341\n",
      "macro avg      0.831236  0.824123  0.827403  3589.00000\n",
      "weighted avg   0.842183  0.843410  0.842561  3589.00000\n",
      "Saved 562 misclassifications to bias_pan_misclassifications.xlsx\n",
      "\n",
      "Top bias features pushing toward AI:\n",
      "                         feature    weight\n",
      "14                      neg_rate  1.482674\n",
      "13                      pos_rate  1.199948\n",
      "1                 sentiment_mean  0.408142\n",
      "0                 assertive_rate  0.391881\n",
      "10     orientation_identity_rate  0.133668\n",
      "11      disability_identity_rate  0.102077\n",
      "8         religion_identity_rate  0.027694\n",
      "9      nationality_identity_rate -0.011181\n",
      "7   race_ethnicity_identity_rate -0.195390\n",
      "15                polarity_score -0.268695\n",
      "4             subjectivity_score -0.299980\n",
      "12             age_identity_rate -0.397164\n",
      "2                  sentiment_var -0.422614\n",
      "6           gender_identity_rate -0.475158\n",
      "5                     hedge_rate -0.537363\n",
      "3                 profanity_rate -0.684859\n",
      "16              categorical_rate -1.162688\n",
      "\n",
      "Top bias features pushing toward Human:\n",
      "                         feature    weight\n",
      "16              categorical_rate -1.162688\n",
      "3                 profanity_rate -0.684859\n",
      "5                     hedge_rate -0.537363\n",
      "6           gender_identity_rate -0.475158\n",
      "2                  sentiment_var -0.422614\n",
      "12             age_identity_rate -0.397164\n",
      "4             subjectivity_score -0.299980\n",
      "15                polarity_score -0.268695\n",
      "7   race_ethnicity_identity_rate -0.195390\n",
      "9      nationality_identity_rate -0.011181\n",
      "8         religion_identity_rate  0.027694\n",
      "11      disability_identity_rate  0.102077\n",
      "10     orientation_identity_rate  0.133668\n",
      "0                 assertive_rate  0.391881\n",
      "1                 sentiment_mean  0.408142\n",
      "13                      pos_rate  1.199948\n",
      "14                      neg_rate  1.482674\n"
     ]
    }
   ],
   "source": [
    "# --- Analysis ---\n",
    "# Full report\n",
    "full_results_output_path = Path(\"2_bias_model_pan_results.xlsx\")\n",
    "report_df.to_excel(full_results_output_path, index=True)\n",
    "\n",
    "print(f\"\\nSaved bias model report to: {full_results_output_path}\")\n",
    "print(report_df)\n",
    "\n",
    "# Misclassifications\n",
    "misclassified_bias = df_val[df_val[\"y_true\"] != df_val[\"y_pred_bias\"]]\n",
    "misclassified_bias_feats = bias_val.loc[misclassified_bias.index]\n",
    "\n",
    "misclassified_bias_full = pd.concat(\n",
    "    [misclassified_bias[[\"id\", \"text\", \"y_true\", \"y_pred_bias\", \"model\", \"genre\"]],\n",
    "    misclassified_bias_feats],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "missclassifications_output_path = Path(\"bias_pan_misclassifications.xlsx\")\n",
    "misclassified_bias_full.to_excel(missclassifications_output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(misclassified_bias_full)} misclassifications to {missclassifications_output_path}\")\n",
    "\n",
    "# --- Check what the bias classifier learned ---\n",
    "handcrafted_df = bias_df.copy()\n",
    "handcrafted_feat_names = list(handcrafted_df.columns)\n",
    "coefs = clf_bias.coef_[0]   # shape = (n_features,)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": handcrafted_feat_names,\n",
    "    \"weight\": coefs\n",
    "})\n",
    "\n",
    "top_ai = coef_df.sort_values(\"weight\", ascending=False).head(20)\n",
    "top_human = coef_df.sort_values(\"weight\", ascending=True).head(20)\n",
    "\n",
    "print(\"\\nTop bias features pushing toward AI:\")\n",
    "print(top_ai)\n",
    "\n",
    "print(\"\\nTop bias features pushing toward Human:\")\n",
    "print(top_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74beb14",
   "metadata": {},
   "source": [
    "# Bias model on migration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa8c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [00:00<00:00, 1351.43it/s]\n",
      "100%|██████████| 522/522 [00:03<00:00, 140.72it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 3359.57it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 1733.85it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 2855.02it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 1521.81it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 2007.11it/s]\n",
      "100%|██████████| 522/522 [00:00<00:00, 1455.84it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1628.84it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 145.94it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 3290.11it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1706.73it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 2828.04it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1484.40it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1960.94it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1469.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(522, 17) (78, 17)\n",
      "[[36  2]\n",
      " [ 1 39]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep original and metadata\n",
    "train_path = Path(training_data_migration)\n",
    "val_path = Path(testing_data_migration)\n",
    "\n",
    "df_train = pd.read_excel(train_path)\n",
    "df_train = df_train[[\"id\", \"text\", \"label\", \"genre\", \"model\"]].copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "# --- Train bias model ---\n",
    "\n",
    "# Load lexicons\n",
    "positive_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\positive-words-dictionary.txt\")\n",
    "negative_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\negative-words-dictionary.txt\")\n",
    "profanity_lexicon = features.load_profanity_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\toxic-words-dictionary.txt\")\n",
    "\n",
    "# Bias features for TRAIN\n",
    "bias_df = pd.concat([\n",
    "    df_train[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_sentiment_features),  # already multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_identity_term_rates),  # multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),  # multi-col (pos_rate, neg_rate, polarity_score)\n",
    "    df_train[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Scale features\n",
    "scaler_bias = StandardScaler()\n",
    "X_train_bias = scaler_bias.fit_transform(bias_df)\n",
    "\n",
    "# Train classifier\n",
    "clf_bias = LogisticRegression(max_iter=1000, verbose=1)\n",
    "clf_bias.fit(X_train_bias, df_train[\"label\"])\n",
    "\n",
    "# --- Bias Feature Classifier Training ---\n",
    "df_val = pd.read_excel(val_path)\n",
    "\n",
    "# Bias features for VAL\n",
    "bias_val = pd.concat([\n",
    "    df_val[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_sentiment_features),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_identity_term_rates),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),\n",
    "    df_val[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Scale using SAME scaler\n",
    "X_val_bias = scaler_bias.transform(bias_val)\n",
    "\n",
    "# Predict\n",
    "y_val_pred = clf_bias.predict(X_val_bias)\n",
    "\n",
    "# Evaluate\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(\n",
    "        df_val[\"label\"], y_val_pred,\n",
    "        target_names=[\"Human\", \"AI\"],\n",
    "        output_dict=True\n",
    "    )\n",
    ").transpose()\n",
    "\n",
    "# Sanity check\n",
    "print(bias_df.isna().sum().sum())\n",
    "print(bias_val.isna().sum().sum())\n",
    "print(bias_df.shape, bias_val.shape)\n",
    "print(confusion_matrix(df_val[\"label\"], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dcc4222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved bias model report to: 2_bias_model_migration_results.xlsx\n",
      "              precision    recall  f1-score    support\n",
      "Human          0.972973  0.947368  0.960000  38.000000\n",
      "AI             0.951220  0.975000  0.962963  40.000000\n",
      "accuracy       0.961538  0.961538  0.961538   0.961538\n",
      "macro avg      0.962096  0.961184  0.961481  78.000000\n",
      "weighted avg   0.961817  0.961538  0.961519  78.000000\n",
      "\n",
      "Top bias features pushing toward AI:\n",
      "                         feature    weight\n",
      "14                      neg_rate  2.183094\n",
      "13                      pos_rate  1.806948\n",
      "1                 sentiment_mean  1.392883\n",
      "12             age_identity_rate  0.101530\n",
      "16              categorical_rate -0.012834\n",
      "15                polarity_score -0.040461\n",
      "5                     hedge_rate -0.076977\n",
      "2                  sentiment_var -0.082457\n",
      "4             subjectivity_score -0.117547\n",
      "0                 assertive_rate -0.138438\n",
      "11      disability_identity_rate -0.325031\n",
      "8         religion_identity_rate -0.735063\n",
      "10     orientation_identity_rate -0.886660\n",
      "9      nationality_identity_rate -1.166516\n",
      "7   race_ethnicity_identity_rate -1.577769\n",
      "3                 profanity_rate -2.122194\n",
      "6           gender_identity_rate -2.185796\n",
      "\n",
      "Top bias features pushing toward Human:\n",
      "                         feature    weight\n",
      "6           gender_identity_rate -2.185796\n",
      "3                 profanity_rate -2.122194\n",
      "7   race_ethnicity_identity_rate -1.577769\n",
      "9      nationality_identity_rate -1.166516\n",
      "10     orientation_identity_rate -0.886660\n",
      "8         religion_identity_rate -0.735063\n",
      "11      disability_identity_rate -0.325031\n",
      "0                 assertive_rate -0.138438\n",
      "4             subjectivity_score -0.117547\n",
      "2                  sentiment_var -0.082457\n",
      "5                     hedge_rate -0.076977\n",
      "15                polarity_score -0.040461\n",
      "16              categorical_rate -0.012834\n",
      "12             age_identity_rate  0.101530\n",
      "1                 sentiment_mean  1.392883\n",
      "13                      pos_rate  1.806948\n",
      "14                      neg_rate  2.183094\n"
     ]
    }
   ],
   "source": [
    "# --- Analysis ---\n",
    "# Full report\n",
    "output_path = Path(\"2_bias_model_migration_results.xlsx\")\n",
    "report_df.to_excel(output_path, index=True)\n",
    "\n",
    "print(f\"\\nSaved bias model report to: {output_path}\")\n",
    "print(report_df)\n",
    "\n",
    "# Check what the bias classifier learned\n",
    "handcrafted_df = bias_df.copy()\n",
    "handcrafted_feat_names = list(handcrafted_df.columns)\n",
    "coefs = clf_bias.coef_[0]   # shape = (n_features,)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": handcrafted_feat_names,\n",
    "    \"weight\": coefs\n",
    "})\n",
    "\n",
    "top_ai = coef_df.sort_values(\"weight\", ascending=False).head(20)\n",
    "top_human = coef_df.sort_values(\"weight\", ascending=True).head(20)\n",
    "\n",
    "print(\"\\nTop bias features pushing toward AI:\")\n",
    "print(top_ai)\n",
    "\n",
    "print(\"\\nTop bias features pushing toward Human:\")\n",
    "print(top_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5e7ba",
   "metadata": {},
   "source": [
    "# Merged model on PAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5173b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23707/23707 [32:44<00:00, 12.07it/s] \n",
      "100%|██████████| 23707/23707 [00:32<00:00, 725.36it/s] \n",
      "100%|██████████| 23707/23707 [00:09<00:00, 2606.39it/s]\n",
      "100%|██████████| 23707/23707 [00:05<00:00, 4184.88it/s]\n",
      "100%|██████████| 23707/23707 [00:21<00:00, 1093.65it/s]\n",
      "100%|██████████| 23707/23707 [00:16<00:00, 1479.82it/s]\n",
      "100%|██████████| 23707/23707 [00:10<00:00, 2181.87it/s]\n",
      "100%|██████████| 23707/23707 [00:30<00:00, 772.77it/s] \n",
      "100%|██████████| 23707/23707 [00:22<00:00, 1074.84it/s]\n",
      "100%|██████████| 23707/23707 [00:15<00:00, 1553.27it/s]\n",
      "100%|██████████| 23707/23707 [02:50<00:00, 139.30it/s]\n",
      "100%|██████████| 23707/23707 [00:13<00:00, 1703.46it/s]\n",
      "100%|██████████| 23707/23707 [00:25<00:00, 941.93it/s] \n",
      "100%|██████████| 23707/23707 [00:15<00:00, 1530.98it/s]\n",
      "100%|██████████| 23707/23707 [00:29<00:00, 794.24it/s] \n",
      "100%|██████████| 23707/23707 [00:21<00:00, 1100.11it/s]\n",
      "100%|██████████| 23707/23707 [00:28<00:00, 827.92it/s] \n",
      "100%|██████████| 3589/3589 [05:48<00:00, 10.31it/s]\n",
      "100%|██████████| 3589/3589 [00:04<00:00, 797.93it/s] \n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2355.86it/s]\n",
      "100%|██████████| 3589/3589 [00:00<00:00, 5465.54it/s]\n",
      "100%|██████████| 3589/3589 [00:03<00:00, 948.46it/s] \n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1209.14it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 1968.78it/s]\n",
      "100%|██████████| 3589/3589 [00:04<00:00, 750.23it/s] \n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1203.76it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1465.40it/s]\n",
      "100%|██████████| 3589/3589 [00:26<00:00, 133.19it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 3282.56it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1764.81it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 2898.15it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1282.04it/s]\n",
      "100%|██████████| 3589/3589 [00:01<00:00, 1977.84it/s]\n",
      "100%|██████████| 3589/3589 [00:02<00:00, 1473.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(23707, 55) (3589, 55)\n",
      "[[1189   88]\n",
      " [  50 2262]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep original and metadata\n",
    "train_path = Path(training_data_pan)\n",
    "val_path = Path(testing_data_pan)\n",
    "\n",
    "df_train = pd.read_json(train_path, lines=True)\n",
    "df_train = df_train[[\"id\", \"text\", \"label\", \"genre\", \"model\"]].copy()\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(int)\n",
    "\n",
    "# --- Train merged model ---\n",
    "\n",
    "# Load lexicons\n",
    "positive_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\positive-words-dictionary.txt\")\n",
    "negative_lexicon = features.load_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\negative-words-dictionary.txt\")\n",
    "profanity_lexicon = features.load_profanity_lexicon(r\"C:\\Users\\andre\\OneDrive\\Desktop\\PAN Task 2025\\toxic-words-dictionary.txt\")\n",
    "\n",
    "# Features from reduced baseline model\n",
    "df_train[\"spacy_doc\"] = df_train[\"text\"].progress_apply(nlp)\n",
    "\n",
    "baseline_train_full = pd.concat([\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_train[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_train[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_train[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Bias features\n",
    "bias_train_full = pd.concat([\n",
    "    df_train[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_sentiment_features),  # already multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_train[\"text\"].progress_apply(features.compute_identity_term_rates),  # multi-col\n",
    "    df_train[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),  # multi-col (pos_rate, neg_rate, polarity_score)\n",
    "    df_train[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Merge all features\n",
    "merged_train_full = pd.concat([baseline_train_full, bias_train_full], axis=1)\n",
    "feature_order = merged_train_full.columns\n",
    "\n",
    "# Scale\n",
    "scaler_merged = StandardScaler()\n",
    "X_train_merged = scaler_merged.fit_transform(merged_train_full)\n",
    "\n",
    "# Train classifier\n",
    "clf_merged = LogisticRegression(max_iter=1000, verbose=1)\n",
    "clf_merged.fit(X_train_merged, df_train[\"label\"])\n",
    "\n",
    "# --- Validate ---\n",
    "df_val = pd.read_json(val_path, lines=True)\n",
    "df_val[\"spacy_doc\"] = df_val[\"text\"].progress_apply(nlp)\n",
    "\n",
    "# Features from reduced baseline model\n",
    "baseline_val_full = pd.concat([\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    df_val[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    df_val[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    df_val[\"spacy_doc\"].progress_apply(features.compute_self_similarity)\n",
    "], axis=1)\n",
    "\n",
    "# Bias features\n",
    "bias_val_full = pd.concat([\n",
    "    df_val[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_sentiment_features),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    df_val[\"text\"].progress_apply(features.compute_identity_term_rates),\n",
    "    df_val[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),\n",
    "    df_val[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "merged_val_full = pd.concat([baseline_val_full, bias_val_full], axis=1)\n",
    "merged_val_full = merged_val_full.reindex(columns=feature_order)\n",
    "\n",
    "# Scale using same scaler\n",
    "X_val_merged = scaler_merged.transform(merged_val_full)\n",
    "\n",
    "# Predict\n",
    "y_val_pred = clf_merged.predict(X_val_merged)\n",
    "\n",
    "df_val = df_val.copy()\n",
    "df_val[\"y_true\"] = df_val[\"label\"]\n",
    "df_val[\"y_pred\"] = y_val_pred\n",
    "\n",
    "# Evaluate\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(\n",
    "        df_val[\"label\"], y_val_pred,\n",
    "        target_names=[\"Human\", \"AI\"],\n",
    "        output_dict=True)\n",
    ").transpose()\n",
    "\n",
    "# Sanity check\n",
    "print(merged_train_full.isna().sum().sum())\n",
    "print(merged_val_full.isna().sum().sum())\n",
    "print(merged_train_full.shape, merged_val_full.shape)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(df_val[\"label\"], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f29fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged model report to: 3_merged_pan_results.xlsx\n",
      "              precision    recall  f1-score      support\n",
      "Human          0.959645  0.931088  0.945151  1277.000000\n",
      "AI             0.962553  0.978374  0.970399  2312.000000\n",
      "accuracy       0.961549  0.961549  0.961549     0.961549\n",
      "macro avg      0.961099  0.954731  0.957775  3589.000000\n",
      "weighted avg   0.961518  0.961549  0.961416  3589.000000\n",
      "Saved 138 misclassifications to merged_pan_misclassifications.xlsx\n",
      "\n",
      "Top merged features pushing toward AI:\n",
      "               feature    weight feature_type\n",
      "26           upos_PRON  2.261831     baseline\n",
      "2        mean_word_len  1.494952     baseline\n",
      "5              punct_,  1.448293     baseline\n",
      "21                 ttr  1.262385     baseline\n",
      "28            upos_DET  1.110786     baseline\n",
      "52            neg_rate  0.999864         bias\n",
      "37    self_sim_jaccard  0.989597     baseline\n",
      "36     rep_5gram_ratio  0.833820     baseline\n",
      "51            pos_rate  0.822653         bias\n",
      "19         digit_ratio  0.570215     baseline\n",
      "0        mean_sent_len  0.566931     baseline\n",
      "11             punct_'  0.525353     baseline\n",
      "39      sentiment_mean  0.491009         bias\n",
      "34           upos_PART  0.380480     baseline\n",
      "18         title_ratio  0.215660     baseline\n",
      "9              punct_?  0.149644     baseline\n",
      "17         upper_ratio  0.132821     baseline\n",
      "3         std_word_len  0.094634     baseline\n",
      "42  subjectivity_score  0.084035         bias\n",
      "13             punct_(  0.043566     baseline\n",
      "\n",
      "Top merged features pushing toward Human:\n",
      "                      feature    weight feature_type\n",
      "4              stopword_ratio -2.843400     baseline\n",
      "7                     punct_; -1.579051     baseline\n",
      "35                 upos_PROPN -1.255422     baseline\n",
      "15                    punct_- -1.050674     baseline\n",
      "1                std_sent_len -1.036793     baseline\n",
      "20                space_ratio -1.034956     baseline\n",
      "24                   upos_ADJ -0.862468     baseline\n",
      "31                   upos_NUM -0.759919     baseline\n",
      "25                   upos_ADV -0.564936     baseline\n",
      "33                  upos_INTJ -0.443324     baseline\n",
      "23                  upos_VERB -0.436430     baseline\n",
      "41             profanity_rate -0.365874         bias\n",
      "10                    punct_! -0.305412     baseline\n",
      "32                   upos_AUX -0.244425     baseline\n",
      "53             polarity_score -0.172855         bias\n",
      "14                    punct_) -0.171282     baseline\n",
      "54           categorical_rate -0.153850         bias\n",
      "22                  upos_NOUN -0.149626     baseline\n",
      "47  nationality_identity_rate -0.132754         bias\n",
      "29                 upos_CCONJ -0.107629     baseline\n"
     ]
    }
   ],
   "source": [
    "# --- Analysis ---\n",
    "# Full report\n",
    "full_results_output_path = Path(\"3_merged_pan_results.xlsx\")\n",
    "report_df.to_excel(full_results_output_path, index=True)\n",
    "\n",
    "print(f\"\\nSaved merged model report to: {full_results_output_path}\")\n",
    "print(report_df)\n",
    "\n",
    "# Misclassifications\n",
    "misclassified = df_val[df_val[\"y_true\"] != df_val[\"y_pred\"]]\n",
    "misclassified_feats = merged_val_full.loc[misclassified.index]\n",
    "\n",
    "misclassified_merged = pd.concat(\n",
    "    [misclassified[[\"id\", \"text\", \"y_true\", \"y_pred\", \"model\", \"genre\"]],\n",
    "    misclassified_feats],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "missclassifications_output_path = Path(\"merged_pan_misclassifications.xlsx\")\n",
    "misclassified_merged.to_excel(missclassifications_output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(misclassified_merged)} misclassifications to {missclassifications_output_path}\")\n",
    "\n",
    "# Check what the merged classifier learned\n",
    "handcrafted_df = merged_train_full.copy()\n",
    "handcrafted_feat_names = list(feature_order)\n",
    "coefs = clf_merged.coef_[0]   # shape = (n_features,)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": handcrafted_feat_names,\n",
    "    \"weight\": coefs\n",
    "})\n",
    "\n",
    "# Tag feature origin\n",
    "coef_df[\"feature_type\"] = np.where(\n",
    "    coef_df[\"feature\"].isin(baseline_train_full.columns),\n",
    "    \"baseline\",\n",
    "    \"bias\"\n",
    ")\n",
    "\n",
    "top_ai = coef_df.sort_values(\"weight\", ascending=False).head(20)\n",
    "top_human = coef_df.sort_values(\"weight\", ascending=True).head(20)\n",
    "\n",
    "print(\"\\nTop merged features pushing toward AI:\")\n",
    "print(top_ai)\n",
    "\n",
    "print(\"\\nTop merged features pushing toward Human:\")\n",
    "print(top_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c01201",
   "metadata": {},
   "source": [
    "# Check a random entry from the PAN data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eee93697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: AI\n",
      "\n",
      "Text excerpt:\n",
      " Brady and Stafford: A Tale of Two Quarterbacks\n",
      "\n",
      "Los Angeles, CA - In a highly anticipated matchup, two of the NFL's most accomplished quarterbacks, Tom Brady and Matthew Stafford, will face off as the Los Angeles Rams host the Tampa Bay Buccaneers. While their paths to their current teams have been  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 359.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1156.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1264.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 400.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 406.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 329.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 369.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 390.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1546.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1078.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1563.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 530.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 658.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 668.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline: Human  (confidence=0.001)\n",
      "\n",
      "Bias: Human  (confidence=0.014)\n",
      "\n",
      "Merged: AI  (confidence=0.583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select random sample\n",
    "i = random.randint(0, len(df_val) - 1)\n",
    "example = df_val.iloc[[i]].copy()\n",
    "text = example[\"text\"].values[0]\n",
    "\n",
    "print(\"Ground truth:\", \"AI\" if example[\"label\"].values[0] == 1 else \"Human\")\n",
    "print(\"\\nText excerpt:\\n\", text[:300], \"...\")\n",
    "\n",
    "# Baseline feature extraction\n",
    "baseline_ex = pd.concat([\n",
    "    example[\"spacy_doc\"].progress_apply(features.extract_length_features),\n",
    "    example[\"spacy_doc\"].progress_apply(features.extract_stopword_rate),\n",
    "    example[\"text\"].progress_apply(features.extract_punct_rates),\n",
    "    example[\"text\"].progress_apply(features.extract_char_class_ratios),\n",
    "    example[\"spacy_doc\"].progress_apply(features.extract_ttr),\n",
    "    example[\"spacy_doc\"].progress_apply(features.extract_upos_freq),\n",
    "    example[\"spacy_doc\"].progress_apply(features.compute_5gram_repetition),\n",
    "    example[\"spacy_doc\"].progress_apply(features.compute_self_similarity),\n",
    "], axis=1)\n",
    "\n",
    "# scale\n",
    "X_base_scaled = scaler.transform(baseline_ex)\n",
    "X_base_sparse = csr_matrix(X_base_scaled)\n",
    "\n",
    "# predict\n",
    "proba_base = clf.predict_proba(X_base_sparse)[0][1]\n",
    "pred_base = clf.predict(X_base_sparse)[0]\n",
    "\n",
    "# Bias feature extraction\n",
    "bias_ex = pd.concat([\n",
    "    example[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_sentiment_features),  # already multi-col\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_identity_term_rates),  # multi-col\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),  # multi-col (pos_rate, neg_rate, polarity_score)\n",
    "    example[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "X_bias_scaled = scaler_bias.transform(bias_ex)\n",
    "proba_bias = clf_bias.predict_proba(X_bias_scaled)[0][1]\n",
    "pred_bias = clf_bias.predict(X_bias_scaled)[0]\n",
    "\n",
    "# Merged feature extraction\n",
    "merged_ex = pd.concat([baseline_ex, bias_ex], axis=1)\n",
    "merged_ex = merged_ex.reindex(columns=feature_order)\n",
    "\n",
    "X_merge_scaled = scaler_merged.transform(merged_ex)\n",
    "proba_merge = clf_merged.predict_proba(X_merge_scaled)[0][1]\n",
    "pred_merge = clf_merged.predict(X_merge_scaled)[0]\n",
    "\n",
    "\n",
    "# Results\n",
    "def show_pred(name, pred, proba):\n",
    "    print(f\"\\n{name}: {'AI' if pred==1 else 'Human'}\"\n",
    "          f\"  (confidence={proba:.3f})\")\n",
    "\n",
    "show_pred(\"Baseline\", pred_base, proba_base)\n",
    "show_pred(\"Bias\", pred_bias, proba_bias)\n",
    "show_pred(\"Merged\", pred_merge, proba_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ee793",
   "metadata": {},
   "source": [
    "# Test it with your own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47a8f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2438.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 350.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2824.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1952.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2641.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1186.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1399.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1974.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASELINE MODEL ===\n",
      "Prediction: AI  (confidence=0.721)\n",
      "\n",
      "Top features pushing toward AI:\n",
      "upos_AUX                         1.6901\n",
      "std_sent_len                     0.9171\n",
      "self_sim_jaccard                 0.7937\n",
      "\n",
      "Top features pushing toward Human:\n",
      "upos_PRON                        -1.2292\n",
      "upos_ADP                         -1.1505\n",
      "std_word_len                     -0.9150\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== BIAS MODEL ===\n",
      "Prediction: Human  (confidence=0.111)\n",
      "\n",
      "Top features pushing toward AI:\n",
      "pos_rate                         1.7573\n",
      "profanity_rate                   1.6289\n",
      "sentiment_mean                   1.2632\n",
      "\n",
      "Top features pushing toward Human:\n",
      "neg_rate                         -4.0221\n",
      "nationality_identity_rate        -3.3572\n",
      "hedge_rate                       -0.1590\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== MERGED MODEL ===\n",
      "Prediction: Human  (confidence=0.196)\n",
      "\n",
      "Top features pushing toward AI:\n",
      "ttr                              4.3853\n",
      "stopword_ratio                   2.5673\n",
      "std_sent_len                     0.9756\n",
      "\n",
      "Top features pushing toward Human:\n",
      "upos_PRON                        -3.5327\n",
      "self_sim_jaccard                 -1.8105\n",
      "upos_ADJ                         -1.6912\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predict_and_explain(model_name, clf, feature_df, scaler, feature_order=None):\n",
    "    # If merged model → enforce identical training column order\n",
    "    if feature_order is not None:\n",
    "        feature_df = feature_df.reindex(columns=feature_order).fillna(0)\n",
    "    else:\n",
    "        feature_df = feature_df.fillna(0)\n",
    "\n",
    "    # Scale\n",
    "    X_scaled = scaler.transform(feature_df)\n",
    "\n",
    "    # Sparse for baseline / merged\n",
    "    X_sparse = csr_matrix(X_scaled)\n",
    "\n",
    "    # Predict\n",
    "    proba = clf.predict_proba(X_sparse)[0][1]\n",
    "    pred  = clf.predict(X_sparse)[0]\n",
    "    pred_label = \"AI\" if pred == 1 else \"Human\"\n",
    "\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Prediction: {pred_label}  (confidence={proba:.3f})\")\n",
    "\n",
    "    # Explain influence\n",
    "    coefs = clf.coef_[0]\n",
    "    vec   = X_sparse.toarray().flatten()\n",
    "    contribs = vec * coefs\n",
    "    feature_names = feature_df.columns.tolist()\n",
    "\n",
    "    top_pos = np.argsort(contribs)[-3:][::-1]\n",
    "    top_neg = np.argsort(contribs)[:3]\n",
    "\n",
    "    print(\"\\nTop features pushing toward AI:\")\n",
    "    for idx in top_pos:\n",
    "        if vec[idx] != 0:\n",
    "            print(f\"{feature_names[idx]:<32} {contribs[idx]:.4f}\")\n",
    "\n",
    "    print(\"\\nTop features pushing toward Human:\")\n",
    "    for idx in top_neg:\n",
    "        if vec[idx] != 0:\n",
    "            print(f\"{feature_names[idx]:<32} {contribs[idx]:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# Manual input\n",
    "my_text = \"\"\"\n",
    "Time moves differently in places wrapped by mountains and quiet valleys; one day feels as patient as a slow climb, another as fleeting as a bird darting through pines. \n",
    "In Switzerland, people often walk to the train or stand at a tram stop and glance up at snow-tipped peaks — almost as if the mountains are part of daily rhythm rather than distant scenery. \n",
    "The multilingual buzz in cafés, from German to French to Italian, carries that subtle sense of multiple worlds coexisting side by side, each greeting the next in its own voice. \n",
    "Everyday order—clean streets, on-time trains, polite commuters—is underpinned by a kind of silent agreement, a willingness to stay small, to notice the detail. \n",
    "And yet under that calm surface there’s movement: ideas flow, debates happen in parliaments and living rooms alike, change sometimes sneaks in as quietly as fog rolling down a slope. \n",
    "I often wonder if that balance—between stillness and motion, tradition and change—keeps Swiss life alive in a way harder to see on glossy postcards. \n",
    "Maybe the real charm lies in how ordinary moments carry a little weight, gentle but firm, as steady as the mountains.\n",
    "\"\"\"\n",
    "\n",
    "# Wrap like a one-row dataset\n",
    "example = pd.DataFrame({\"text\": [my_text]})\n",
    "example[\"spacy_doc\"] = example[\"text\"].apply(nlp)\n",
    "\n",
    "\n",
    "# === Extract each model's feature set exactly like training ===\n",
    "\n",
    "# Baseline features\n",
    "baseline_ex = pd.concat([\n",
    "    example[\"spacy_doc\"].apply(features.extract_length_features),\n",
    "    example[\"spacy_doc\"].apply(features.extract_stopword_rate),\n",
    "    example[\"text\"].apply(features.extract_punct_rates),\n",
    "    example[\"text\"].apply(features.extract_char_class_ratios),\n",
    "    example[\"spacy_doc\"].apply(features.extract_ttr),\n",
    "    example[\"spacy_doc\"].apply(features.extract_upos_freq),\n",
    "    example[\"spacy_doc\"].apply(features.compute_5gram_repetition),\n",
    "    example[\"spacy_doc\"].apply(features.compute_self_similarity),\n",
    "], axis=1)\n",
    "\n",
    "# Bias features\n",
    "bias_ex = pd.concat([\n",
    "    example[\"text\"].progress_apply(features.compute_assertive_rate).rename(\"assertive_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_sentiment_features),  # already multi-col\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_profanity_rate(t, profanity_lexicon)).rename(\"profanity_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_subjectivity_score).rename(\"subjectivity_score\"),\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_hedge_rate(t, features.hedge_lexicon)).rename(\"hedge_rate\"),\n",
    "    example[\"text\"].progress_apply(features.compute_identity_term_rates),  # multi-col\n",
    "    example[\"text\"].progress_apply(lambda t: features.compute_emotional_tone_from_lexicons(\n",
    "        t, positive_lexicon, negative_lexicon\n",
    "    )),  # multi-col (pos_rate, neg_rate, polarity_score)\n",
    "    example[\"text\"].progress_apply(features.compute_categorical_rate).rename(\"categorical_rate\"),\n",
    "], axis=1)\n",
    "\n",
    "# Full merged set (same build as training)\n",
    "merged_ex = pd.concat([baseline_ex, bias_ex], axis=1)\n",
    "\n",
    "\n",
    "# ===== Run all three models =====\n",
    "predict_and_explain(\"BASELINE MODEL\", clf, baseline_ex, scaler)\n",
    "predict_and_explain(\"BIAS MODEL\", clf_bias, bias_ex, scaler_bias)\n",
    "predict_and_explain(\"MERGED MODEL\", clf_merged, merged_ex, scaler_merged, feature_order)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
